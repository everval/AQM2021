{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lecture2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/everval/AQM2021/blob/main/Lecture2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qi3e8MgUfaVY"
      },
      "source": [
        "# Probability Distributions and the Central Limit Theorem \n",
        "\n",
        "Every day we are confronted with situations with uncertain outcomes: the flipping of a coin, roll of a dice. These experiments have in common that the outcome is not predetermined. This in the sense that before we run the experiment, we do not know the outcome.\n",
        "\n",
        "The above are classical, and intuitive, experiments in probability. Nonetheless, we encounter several measures of uncertainty when working with data: sampling, input errors. \n",
        "\n",
        "We are interested in modelling and measuring these uncertainties, using probability theory, to take better informed decisions.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iECYQrAyBoqp"
      },
      "source": [
        "## Normal distribution\n",
        "\n",
        "Today, we start by discussing the Normal distribution, the most used probability distribution.\n",
        "\n",
        "As usual, we start by loading the Python packages that we are going to use in the analysis. Remembering to load also the random package.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GP22-79G-w_u"
      },
      "source": [
        "import numpy as np #Package for numerical multidimensional tables\n",
        "import pandas as pd #Package for data frames\n",
        "import matplotlib.pyplot as plt #Package for plots and graphs\n",
        "import random as rnd #Package for random number generation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zg9CDehJ-7Xv"
      },
      "source": [
        "Formally, the Normal distribution is a **continous** distribution. That is, it takes values on a continuum of values. In its case, the whole real line.\n",
        "\n",
        "We say that $X$ follows the Normal distribution with mean $\\mu$ and standard deviation $\\sigma$ if its probabiliy density function (or **pdf** for short), $f(x)$ is given by\n",
        "$$f(x) = \\frac{1}{\\sqrt{2\\pi}\\sigma} e^{-\\frac{1}{2}(\\frac{x-\\mu}{\\sigma})^2}.$$\n",
        "\n",
        "We write $X\\sim N(\\mu,\\sigma)$ to denote that $X$ follows the Normal distribution with mean $\\mu$ and standard deviation $\\sigma$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBeNer-D5eWu"
      },
      "source": [
        "We can use the probability density function to obtain a graph of the distribution.\n",
        "\n",
        "We make $\\mu=0$ and $\\sigma=1$ to obtain the **standard Normal distribution**.\n",
        "\n",
        "The standard Normal takes its name from the fact that we can standardize any other Normal variable.\n",
        "\n",
        "> Let $X\\sim N(\\mu,\\sigma)$ and let $$Y=\\frac{X-\\mu}{\\sigma},$$ then $Y\\sim N(0,1)$.\n",
        "\n",
        "Recall to import **norm** from the scipy.stats package to have access to functions associated to the Normal distribution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPIe-HIC5ccR"
      },
      "source": [
        " #Import the Normal distribution from the scipy.stats package\n",
        "\n",
        "  #We use the np.arange() function to generate a list of real numbers\n",
        "                                  #np.arange() extends the range() function for integer numbers\n",
        "\n",
        " #Evaluating the pdf\n",
        "\n",
        "plt.plot(vals,norvals,color=\"blue\")  #Plotting the density\n",
        "plt.axvline(0,color=\"black\",linestyle=\"--\")    #Adding vertical line at the mean\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7KJM7BrXjSqe"
      },
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_C3sWhCKca6"
      },
      "source": [
        "Some properties of the Normal distribution:\n",
        "\n",
        "*  \n",
        "*   \n",
        "*\n",
        "* \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcUSyCjfqfTc"
      },
      "source": [
        "The mean of the distribution determines the location of the center of the graph. \n",
        "\n",
        "The shape of the graph does not change by changing the mean, but the graph is translated horizontally.\n",
        "\n",
        "The standard deviation or *scale* parameter does change the shape (as you will show in the exercises)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YXtWBvWIpNkF"
      },
      "source": [
        "new_vals = list(np.arange(-6,6,0.05))  #New grid\n",
        "val_locs =     #Different location parameters\n",
        "\n",
        "for i in range(0,5):\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCQK-mW9gTmd"
      },
      "source": [
        "### Computing probabilities\n",
        "\n",
        "The Normal distribution can take all values in the real line (recall that it is continuous).\n",
        "\n",
        "Given that it is a probability distribution, the probability for all possible values should *add* to 1. For continuous distributions, the *sum* is replaced by the integral.\n",
        "\n",
        "Thus, \n",
        "$$\\int_{-\\infty}^{\\infty} f(x) = \\int_{-\\infty}^{\\infty} \\frac{1}{\\sqrt{2\\pi}\\sigma} e^{-\\frac{1}{2}(\\frac{x-\\mu}{\\sigma})^2} = 1$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3CLyYpzjPE7"
      },
      "source": [
        "Contrasting the Normal distribution against the binomial, a discrete distribution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0cf7kq7ABaqE"
      },
      "source": [
        "from scipy.stats import binom  #Importing the binomial distribution\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "bin_vals = \n",
        "binomial =  #Evaluate the probability for a B(10,0.2)\n",
        "plt.vlines(bin_vals ,0, binomial, linewidth=8)\n",
        "plt.title('Binomial')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "vals = list(np.arange(-4,4,0.05))  \n",
        "norvals =  #Evaluating the standad normal pdf\n",
        "plt.plot(vals,norvals)  #Plotting the density\n",
        "plt.title('Normal')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "duMziSZ7Rz1v"
      },
      "source": [
        "Recall that all probabilities should sum to 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7G8PBj50F1VX",
        "outputId": "c8f0b88d-c957-4058-c13c-d6c67dbd09b8"
      },
      "source": [
        "#Sum all probabilities for the binomial"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9999998976000005"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-qB2bp_H4u7"
      },
      "source": [
        "For continuous distributions, we compute probabilities by\n",
        "$$Pr(a<X<b) = \\int_{a}^{b} f(x).$$\n",
        "\n",
        "\n",
        "For example, we can show how to compute $Pr(X<1)$ graphically."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qHkdZ55JEV9"
      },
      "source": [
        "vals = np.arange(-4,4,0.01)\n",
        "  #Plot the standard Normal\n",
        "\n",
        "probx = np.arange(-4,1,0.01)\n",
        "plt.fill_between(probx,norm.pdf(probx),alpha=0.5, color='r')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z537EcO7MWYk"
      },
      "source": [
        "We can evaluate the probability directly."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97COtj_TMVl9"
      },
      "source": [
        " #Probability that X is less than 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvXK2Hv_hm19"
      },
      "source": [
        "Another useful property of the Normal distribution is that approximately 95% of the probability is contained in the interval given by \n",
        "$$[\\mu-2*\\sigma,\\mu+2*\\sigma].$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WerX3DCLih3V"
      },
      "source": [
        "mu = \n",
        "sig = \n",
        " #Compute probability for the interval"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rF1tw54e4jb7"
      },
      "source": [
        "vals = np.arange(-4,4,0.01)\n",
        "plt.plot(vals, norm.pdf(vals))\n",
        "\n",
        "probx = np.arange(-2,2,0.01)\n",
        "plt.fill_between(probx,norm.pdf(probx),alpha=0.5, color='r')\n",
        "plt.text(-1,0.05,\"P(A)=0.95\",fontsize=18)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zMDmNgG6EdsQ"
      },
      "source": [
        "### Random Normal number generation\n",
        "\n",
        "For some analysis, like Monte Carlo simulation discussed last time, it may be useful to draw samples from the Normal distribution.\n",
        "\n",
        "We can accomplish this by using the *norm.rvs()* function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vzOHf9tFIH7j"
      },
      "source": [
        "sample =  #Generating a random sample from the N(10,2) distribution\n",
        "\n",
        "vals = np.arange(4,16,0.1)  #Making a new grid\n",
        "nor_vals =  #Evaluating the Normal pdf at the grid values\n",
        "\n",
        "          #Creating the histogram of the random sample\n",
        "                                        \n",
        "\n",
        "plt.plot(vals,nor_vals,color=\"red\",linestyle=\"--\") #Adding the theoretical density\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gcw9pv2iPwaZ"
      },
      "source": [
        "### Our Simpsons example\n",
        "\n",
        "We compare the histogram from The Simpsons ratings dataset to a Normal distribution with same mean and standard deviation.\n",
        "\n",
        "First we load the data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ddEVa8IDPvCl"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "simpsons = pd.read_csv('Simpsons_ratings.csv')\n",
        "print(simpsons)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0KJHLtIRQkx"
      },
      "source": [
        "We then create the histogram and compute the mean and standard deviation to add the Normal distribution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AihPqX8RdBk"
      },
      "source": [
        " #Creating the histogram of the random sample\n",
        "\n",
        "plt.title('Simpsons Ratings')\n",
        "\n",
        "mean_simpsons =  #Compute mean of Simpsons ratings\n",
        "std_simpsons =   #Compute standar deviation of Simpsons ratings\n",
        "\n",
        "display([mean_simpsons,std_simpsons])\n",
        "\n",
        "vals = np.arange(3,10,0.1)  #Making a new grid\n",
        "nor_vals = norm.pdf(vals,loc=mean_simpsons,scale=std_simpsons) #Evaluating the Normal\n",
        "\n",
        "plt.plot(vals,nor_vals,color=\"red\",linestyle=\"--\") #Adding the theoretical density\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CMOGoppeTINI"
      },
      "source": [
        "The histogram does not exactly corresponds to the Normal distribution. \n",
        "\n",
        "This could be given that the data indeed does not follow a Normal distribution, or sampling uncertainty as our simulated example above.\n",
        "\n",
        "We could create subsamples fom the Simpsons ratings to study the effect of sampling."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFiroe_J-p2B"
      },
      "source": [
        "## Central Limit Theorem\n",
        "\n",
        "In the previous lecture, we talked about the law of large numbers. It states that\n",
        "$\\bar{X}\\to\\mu$ as $n\\to\\infty$, or, in other words, that $\\bar{X}\\approx\\mu$ if $n$ is large.\n",
        "\n",
        "Nonetheless, the law of large numbers does not tells us how accurate this approximation is. Nor it tells us the speed to which it *converges*.\n",
        "\n",
        "The next theorem gives the answer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZGdAcZBDsF3"
      },
      "source": [
        "> **Central Limit Theorem (CLT)**: Let $X_1,X_2,\\cdots,X_n$ be a sequence of i.i.d. random variables with mean $\\mu$ and standard deviation $\\sigma$. Let $\\bar{X}=\\frac{1}{n}(X_1+X_2+\\cdots+X_n)$ be the sample mean. Then, \n",
        "$$\\bar{X}\\xrightarrow[]{d}N(\\mu,\\frac{\\sigma}{\\sqrt{n}})$$\n",
        "\n",
        "In words, the CLT tells us that the sampling distribution of the sample mean is, at least approximately, normally distributed, regardless of the distribution of the underlying random sample. \n",
        "\n",
        "In fact, the CLT applies regardless of whether the distribution of the $X_i$ is discrete (for example, Poisson or binomial) or continuous (for example, exponential or chi-square)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndlKoX6NGF8_"
      },
      "source": [
        "### Monte Carlo Simulation\n",
        "\n",
        "Building on the idea of last lecture, we use Monte Carlo simulation to see the CLT in action.\n",
        "\n",
        "Recall that our coin game is discrete. There are only two possible outcomes with equal probability."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSY3FjncGlX0"
      },
      "source": [
        "def coin_flip(p):\n",
        "    return(1*(rnd.random()>=p))\n",
        "\n",
        "def game(n,p=0.5):\n",
        "    draw = []\n",
        "    for i in range(0,n):\n",
        "            draw.append(coin_flip(p))\n",
        "    return(draw)\n",
        "\n",
        "coin_mean = np.mean(game(10))\n",
        "display(coin_mean)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SI_ue7x1JgpE"
      },
      "source": [
        "      # Initialize a vector, xbars, to store the sample means\n",
        "N = 1000     #Size of the sample\n",
        "n = 1000    #Number of samples\n",
        "\n",
        "   #Play the game n times\n",
        "   #Append the mean of the result of the game to xbars\n",
        "\n",
        "plt.hist(xbars,bins=10,density=True)\n",
        "plt.title('Sample means for different samples of same size')\n",
        "\n",
        "mean_xbars =   #Compute the population mean\n",
        "                              #Alternatively we can approximate the theoretial \n",
        "                              #mean with the mean of the sample means\n",
        "std_xbars =  #Compute the standard deviation\n",
        "\n",
        "vals = np.arange(mean_xbars-0.2,mean_xbars+0.2,0.005)  #Making a new grid\n",
        "nor_vals = norm.pdf(vals,loc=mean_xbars,scale=std_xbars) #Evaluating the Normal\n",
        "\n",
        "plt.plot(vals,nor_vals,color=\"red\",linestyle=\"--\") #Adding the theoretical density\n",
        "plt.xlim(mean_xbars-0.2,mean_xbars+0.2)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emWIJ8roMJvr"
      },
      "source": [
        "The CLT tells us the *speed* to which the sample means converge to the theoretical mean. \n",
        "\n",
        "In particular, the $\\sqrt{n}$ term tells us that the sample means converge at *square root speed*.\n",
        "\n",
        "Bigger sample sizes are always better. But in practical terms, we need to square the size of the sample to see a *significant* better approximation. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KJjxtw8NJgs"
      },
      "source": [
        "xbars100 = []  # Initialize a vector to store the sample means of size 100\n",
        "xbars10000 = []  # Initialize a vector to store the sample means of size 10,000\n",
        "n = 1000    #Number of samples\n",
        "\n",
        "for i in range(0,N): #Play the game n times\n",
        "  xbars100.append(  ) #Append the mean of the result of the game to xbars\n",
        "  xbars10000.append(np.mean(game(10000)))\n",
        "\n",
        "plt.subplot(1,2,1)\n",
        "plt.title('Samples of size 100')\n",
        "plt.hist(xbars100,bins=10,density=True)\n",
        "std_xbars100 = np.sqrt(0.25)/np.sqrt(100)\n",
        "vals = np.arange(mean_xbars-0.2,mean_xbars+0.2,0.005)  #Making a new grid\n",
        "nor_vals = norm.pdf(vals,loc=mean_xbars,scale=std_xbars100) #Evaluating the Normal\n",
        "plt.plot(vals,nor_vals,color=\"red\",linestyle=\"--\") #Adding the theoretical density\n",
        "plt.xlim(mean_xbars-0.2,mean_xbars+0.2)\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.title('Samples of size 10,000')\n",
        "plt.hist(xbars10000,bins=10,density=True)\n",
        "std_xbars10000 = np.sqrt(0.25)/np.sqrt(10000)\n",
        "vals = np.arange(mean_xbars-0.05,mean_xbars+0.05,0.005)  #Making a new grid\n",
        "nor_vals = norm.pdf(vals,loc=mean_xbars,scale=std_xbars10000) #Evaluating the Normal\n",
        "plt.plot(vals,nor_vals,color=\"red\",linestyle=\"--\") #Adding the theoretical density\n",
        "plt.xlim(mean_xbars-0.05,mean_xbars+0.05)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "joa3eWhNO3Tl"
      },
      "source": [
        "### Our Simpsons example\n",
        "\n",
        "To show the CLT in work, we need several samples of Simpsons ratings. Nonetheless, we only have access to one sample. \n",
        "\n",
        "One way to generate *new* datasets from a given one is to sample with replacement.\n",
        "\n",
        "Note: If we select the same sample size as the original sample, the method is called **bootstrap**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ySlP0SnPPlwM"
      },
      "source": [
        "samsize = 300 #Sample size\n",
        "numsam = 1000  #Number of samples\n",
        "\n",
        "simpsons_means = []\n",
        "\n",
        "for i in range(0,numsam):\n",
        "  this_sample =   #Obtain a sample of size samsize with replacement\n",
        "  simpsons_means.append(np.mean(this_sample))\n",
        "\n",
        "plt.hist(simpsons_means, bins=10, density=True) #Creating the histogram of the random sample\n",
        "                                        #We make the option density true so the bins sum to 1\n",
        "plt.title('Simpsons Ratings sample mean distribution')\n",
        "\n",
        "std_other = #Compute the standard deviation\n",
        "vals = np.arange(7,7.5,0.025)\n",
        "nor_vals = norm.pdf(vals,loc=mean_simpsons,scale=std_other) #Evaluating the Normal\n",
        "\n",
        "plt.plot(vals,nor_vals,color=\"red\",linestyle=\"--\") #Adding the theoretical density\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9T7K16TE1X-e"
      },
      "source": [
        "The Normal distribution looks like a good fit, which is not surprising given the CLT. \n",
        "\n",
        "Recalling the mean and standard deviation from the **whole** sample, we can write the distribution for the sample mean of the Simpsons ratings.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bCUFadGI1MO_"
      },
      "source": [
        "display([mean_simpsons,std_simpsons])\n",
        "\n",
        "mu = #Sample mean\n",
        "sigma = #Standard deviation of the sample mean\n",
        "\n",
        "display([mu,sigma])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AFdrm_-91Izj"
      },
      "source": [
        "Given the CLT, the Simpsons ratings follow a $N(7.197,0.032)$ distribution. \n",
        "\n",
        "We can use this distribution to compute the probabiliy that the sample mean for the Simpsons ratings is above Family Guy's sample mean (as you will do in the exercises)."
      ]
    }
  ]
}